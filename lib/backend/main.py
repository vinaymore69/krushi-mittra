import sys
import google.generativeai as genai
import speech_recognition as sr
from googletrans import Translator
from gtts import gTTS
import pygame
from PIL import Image
import os
import tempfile
import re
import warnings
import time
import base64
import io
import wave
import struct

# Try to import pydub, but don't fail if FFmpeg is missing
try:
    from pydub import AudioSegment
    PYDUB_AVAILABLE = True
except Exception as e:
    print(f"âš ï¸ pydub not available or FFmpeg missing: {e}")
    PYDUB_AVAILABLE = False

# Suppress warnings
warnings.filterwarnings("ignore")

class MultilingualFarmerAgent:
    def __init__(self, gemini_api_key):
        # Initialize Gemini
        genai.configure(api_key=gemini_api_key)
        self.model = genai.GenerativeModel('gemini-2.0-flash-exp')

        # Initialize other services
        self.translator = Translator()
        self.recognizer = sr.Recognizer()

        # Initialize pygame for audio playback
        pygame.mixer.init()

        # Updated language mapping to match Flutter app
        self.supported_languages = {
            'en': {'name': 'English', 'tts_code': 'en', 'display': 'English', 'sr_code': 'en-US'},
            'hi': {'name': 'à¤¹à¤¿à¤¨à¥à¤¦à¥€', 'tts_code': 'hi', 'display': 'à¤¹à¤¿à¤¨à¥à¤¦à¥€', 'sr_code': 'hi-IN'},
            'mr': {'name': 'à¤®à¤°à¤¾à¤ à¥€', 'tts_code': 'mr', 'display': 'à¤®à¤°à¤¾à¤ à¥€', 'sr_code': 'mr-IN'},
            'pa': {'name': 'à¨ªà©°à¨œà¨¾à¨¬à©€', 'tts_code': 'pa', 'display': 'à¨ªà©°à¨œà¨¾à¨¬à©€', 'sr_code': 'pa-IN'},
            'kn': {'name': 'à²•à²¨à³à²¨à²¡', 'tts_code': 'kn', 'display': 'à²•à²¨à³à²¨à²¡', 'sr_code': 'kn-IN'},
            'ta': {'name': 'à®¤à®®à®¿à®´à¯', 'tts_code': 'ta', 'display': 'à®¤à®®à®¿à®´à¯', 'sr_code': 'ta-IN'},
            'te': {'name': 'à°¤à±†à°²à±à°—à±', 'tts_code': 'te', 'display': 'à°¤à±†à°²à±à°—à±', 'sr_code': 'te-IN'},
            'ml': {'name': 'à´®à´²à´¯à´¾à´³à´‚', 'tts_code': 'ml', 'display': 'à´®à´²à´¯à´¾à´³à´‚', 'sr_code': 'ml-IN'},
            'gu': {'name': 'àª—à«àªœàª°àª¾àª¤à«€', 'tts_code': 'gu', 'display': 'àª—à«àªœàª°àª¾àª¤à«€', 'sr_code': 'gu-IN'},
            'bn': {'name': 'à¦¬à¦¾à¦‚à¦²à¦¾', 'tts_code': 'bn', 'display': 'à¦¬à¦¾à¦‚à¦²à¦¾', 'sr_code': 'bn-IN'},
            'or': {'name': 'à¬“à¬¡à¬¼à¬¿à¬†', 'tts_code': 'or', 'display': 'à¬“à¬¡à¬¼à¬¿à¬†', 'sr_code': 'or-IN'},
            'ur': {'name': 'Ø§Ø±Ø¯Ùˆ', 'tts_code': 'ur', 'display': 'Ø§Ø±Ø¯Ùˆ', 'sr_code': 'ur-PK'}
        }

        # Language name to code mapping for Flutter integration
        self.language_name_to_code = {
            'English': 'en',
            'à¤¹à¤¿à¤¨à¥à¤¦à¥€': 'hi',
            'à¤®à¤°à¤¾à¤ à¥€': 'mr',
            'à¨ªà©°à¨œà¨¾à¨¬à©€': 'pa',
            'à²•à²¨à³à²¨à²¡': 'kn',
            'à®¤à®®à®¿à®´à¯': 'ta',
            'à°¤à±†à°²à±à°—à±': 'te',
            'à´®à´²à´¯à´¾à´³à´‚': 'ml',
            'àª—à«àªœàª°àª¾àª¤à«€': 'gu',
            'à¦¬à¦¾à¦‚à¦²à¦¾': 'bn',
            'à¬“à¬¡à¬¼à¬¿à¬†': 'or',
            'Ø§Ø±Ø¯Ùˆ': 'ur'
        }

    def get_language_code_from_name(self, language_name):
        """Convert language name to language code"""
        return self.language_name_to_code.get(language_name, 'en')

    def get_language_name(self, language_code):
        """Get language name from code"""
        return self.supported_languages.get(language_code, {}).get('name', 'English')

    def get_supported_languages(self):
        """Return supported languages for the dropdown"""
        return [
            {'code': code, 'name': data['name'], 'display': data['display']}
            for code, data in self.supported_languages.items()
        ]

    def save_base64_audio_to_file(self, base64_data):
        """Enhanced audio file saving with better error handling"""
        try:
            print(f"ğŸ“¥ Received base64 audio data (length: {len(base64_data)} chars)")

            # Remove data URL prefix if present
            if base64_data.startswith('data:'):
                header, base64_data = base64_data.split(',', 1)
                print(f"ğŸ“‹ Detected data URL header: {header}")

            # Decode base64 data
            try:
                audio_bytes = base64.b64decode(base64_data)
                print(f"âœ… Successfully decoded base64 data: {len(audio_bytes)} bytes")
            except Exception as decode_error:
                print(f"âŒ Base64 decode error: {decode_error}")
                return None

            # Create a unique temporary file with proper suffix
            timestamp = int(time.time() * 1000)
            temp_dir = tempfile.gettempdir()
            temp_path = os.path.join(temp_dir, f"audio_{timestamp}.wav")

            print(f"ğŸ“ Temp directory: {temp_dir}")
            print(f"ğŸ“ Creating temp file: {temp_path}")

            # Write bytes to file
            try:
                with open(temp_path, 'wb') as temp_file:
                    temp_file.write(audio_bytes)

                # Verify file was created and has content
                if os.path.exists(temp_path):
                    file_size = os.path.getsize(temp_path)
                    print(f"âœ… Audio file created successfully: {temp_path}")
                    print(f"ğŸ“Š File size: {file_size} bytes")

                    if file_size == 0:
                        print("âš ï¸ Warning: Audio file is empty")
                        os.unlink(temp_path)
                        return None

                    return temp_path
                else:
                    print("âŒ File was not created")
                    return None

            except Exception as write_error:
                print(f"âŒ File write error: {write_error}")
                return None

        except Exception as e:
            print(f"âŒ Error in save_base64_audio_to_file: {e}")
            return None

    def is_valid_wave_file(self, file_path):
        """Check if the file is a valid WAV file"""
        try:
            with wave.open(file_path, 'rb') as wav_file:
                # Get basic info
                frames = wav_file.getnframes()
                sample_rate = wav_file.getframerate()
                channels = wav_file.getnchannels()
                sample_width = wav_file.getsampwidth()

                print(f"ğŸ“Š WAV file info: {frames} frames, {sample_rate}Hz, {channels} channels, {sample_width} bytes/sample")

                # Check if it has actual audio data
                if frames > 0:
                    return True
                else:
                    print("âš ï¸ WAV file has no audio frames")
                    return False

        except Exception as e:
            print(f"âŒ Invalid WAV file: {e}")
            return False

    def convert_to_wav_basic(self, input_path):
        """Basic conversion without FFmpeg - works with simple formats"""
        try:
            print(f"ğŸ”„ Attempting basic WAV conversion for: {input_path}")

            # First, check if it's already a valid WAV file
            if self.is_valid_wave_file(input_path):
                print("âœ… File is already a valid WAV file")
                return input_path

            # Try to read as raw audio data and create a proper WAV file
            with open(input_path, 'rb') as f:
                audio_data = f.read()

            # Check if this looks like it might be raw PCM data
            if len(audio_data) > 44:  # Must be larger than WAV header
                # Try to create a WAV file assuming 16kHz, mono, 16-bit
                output_path = input_path.replace('.wav', '_fixed.wav')

                # Create WAV header for 16kHz, mono, 16-bit PCM
                sample_rate = 16000
                channels = 1
                bits_per_sample = 16

                # Skip potential existing headers and try to find PCM data
                # Look for patterns that suggest this is audio data
                potential_data = audio_data[44:] if len(audio_data) > 44 else audio_data

                with wave.open(output_path, 'wb') as wav_file:
                    wav_file.setnchannels(channels)
                    wav_file.setsampwidth(bits_per_sample // 8)
                    wav_file.setframerate(sample_rate)
                    wav_file.writeframes(potential_data)

                # Test if the created file is valid
                if self.is_valid_wave_file(output_path):
                    print(f"âœ… Successfully created WAV file: {output_path}")
                    return output_path
                else:
                    print("âŒ Created WAV file is not valid")
                    if os.path.exists(output_path):
                        os.unlink(output_path)

            print("âŒ Could not convert to valid WAV format")
            return None

        except Exception as e:
            print(f"âŒ Basic WAV conversion error: {e}")
            return None

    def convert_audio_format(self, input_path):
        """Convert audio with fallback methods"""
        try:
            print(f"ğŸ”„ Converting audio format from {input_path}")

            # Method 1: Check if it's already a valid WAV
            if self.is_valid_wave_file(input_path):
                print("âœ… File is already a valid WAV file")
                return input_path

            # Method 2: Try pydub if available
            if PYDUB_AVAILABLE:
                try:
                    print("ğŸ”„ Trying pydub conversion...")
                    audio = AudioSegment.from_file(input_path)

                    # Convert to optimal format for speech recognition
                    audio = audio.set_frame_rate(16000)
                    audio = audio.set_channels(1)
                    audio = audio.set_sample_width(2)

                    # Create output path
                    output_path = input_path.replace('.wav', '_pydub.wav')
                    audio.export(output_path, format="wav")

                    if self.is_valid_wave_file(output_path):
                        print(f"âœ… pydub conversion successful: {output_path}")
                        return output_path
                    else:
                        print("âŒ pydub conversion produced invalid file")
                        if os.path.exists(output_path):
                            os.unlink(output_path)

                except Exception as pydub_error:
                    print(f"âŒ pydub conversion failed: {pydub_error}")

            # Method 3: Try basic conversion
            converted_path = self.convert_to_wav_basic(input_path)
            if converted_path:
                return converted_path

            # Method 4: Try to use the original file directly
            print("âš ï¸ Using original file without conversion")
            return input_path

        except Exception as e:
            print(f"âŒ Audio conversion error: {e}")
            return input_path

    def speech_to_text_with_language(self, audio_file_path, language_code):
        """Enhanced speech recognition with better error handling"""
        print(f"ğŸ¤ Processing audio file: {audio_file_path} for language: {language_code}")

        # Check if file exists
        if not os.path.exists(audio_file_path):
            error_msg = f"Audio file not found: {audio_file_path}"
            print(f"âŒ {error_msg}")
            return error_msg

        # Get file size
        try:
            file_size = os.path.getsize(audio_file_path)
            print(f"ğŸ“Š Original file size: {file_size} bytes")

            if file_size == 0:
                return "Audio file is empty"

        except Exception as e:
            print(f"âŒ Error checking file size: {e}")
            return f"Error accessing audio file: {e}"

        # Get the speech recognition code for the selected language
        lang_data = self.supported_languages.get(language_code, self.supported_languages['en'])
        sr_code = lang_data['sr_code']
        lang_name = lang_data['name']

        print(f"ğŸŒ Using language: {lang_name} ({sr_code})")

        # Convert audio to compatible format
        converted_path = self.convert_audio_format(audio_file_path)
        if not converted_path:
            return "Could not process audio file format"

        try:
            # Try multiple approaches for loading the audio file
            audio_data = None

            # Approach 1: Direct WAV file loading
            if self.is_valid_wave_file(converted_path):
                try:
                    with sr.AudioFile(converted_path) as source:
                        print("âœ… Audio file loaded as WAV")
                        self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                        audio_data = self.recognizer.record(source)
                except Exception as wav_error:
                    print(f"âŒ WAV loading failed: {wav_error}")

            # Approach 2: Try loading as different formats
            if audio_data is None:
                for file_ext in ['.wav', '.flac', '.aiff']:
                    try:
                        temp_renamed = converted_path + file_ext
                        if converted_path != temp_renamed:
                            # Copy to temp file with different extension
                            import shutil
                            shutil.copy2(converted_path, temp_renamed)

                            with sr.AudioFile(temp_renamed) as source:
                                print(f"âœ… Audio loaded as {file_ext}")
                                self.recognizer.adjust_for_ambient_noise(source, duration=0.5)
                                audio_data = self.recognizer.record(source)
                                break

                    except Exception as ext_error:
                        print(f"âŒ Failed to load as {file_ext}: {ext_error}")
                        continue
                    finally:
                        # Clean up temp renamed file
                        if 'temp_renamed' in locals() and os.path.exists(temp_renamed):
                            try:
                                os.unlink(temp_renamed)
                            except:
                                pass

            if audio_data is None:
                return "Could not load audio file for speech recognition"

            print("ğŸ“¼ Audio data ready for recognition")

            # Try recognition with the specified language
            try:
                print(f"ğŸ” Attempting recognition for {lang_name}...")
                text = self.recognizer.recognize_google(
                    audio_data,
                    language=sr_code,
                    show_all=False
                )

                if text and text.strip():
                    print(f"âœ… Recognition successful: '{text}'")
                    return text.strip()
                else:
                    return f"No speech detected in the {lang_name} audio"

            except sr.UnknownValueError:
                print(f"âš ï¸ Could not understand {lang_name} audio, trying fallback...")

                # Try with English as fallback
                try:
                    text = self.recognizer.recognize_google(audio_data, language='en-US')
                    if text and text.strip():
                        print(f"âœ… Fallback recognition (English): '{text}'")
                        # Translate to target language if needed
                        if language_code != 'en':
                            try:
                                translated = self.translator.translate(text, dest=language_code)
                                return f"{text} (Translated: {translated.text})"
                            except:
                                return text
                        return text.strip()
                except sr.UnknownValueError:
                    return f"Could not understand the audio in any language"

            except sr.RequestError as e:
                print(f"âŒ Google Speech Recognition error: {e}")
                return f"Speech recognition service error: {e}"

        except Exception as e:
            error_msg = f"Error processing audio file: {e}"
            print(f"âŒ {error_msg}")
            return error_msg

        finally:
            # Clean up converted file if it's different from original
            if converted_path != audio_file_path and os.path.exists(converted_path):
                try:
                    os.unlink(converted_path)
                    print("ğŸ—‘ï¸ Cleaned up converted audio file")
                except:
                    pass

    def process_text_query(self, text, target_language="hi"):
        """Process text-based query in selected language"""
        try:
            lang_data = self.supported_languages.get(target_language, self.supported_languages['hi'])
            lang_name = lang_data['name']

            # Language-specific prompts for better compliance
            language_prompts = {
                'pa': "à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨¸à¨¿à¨°à¨«à¨¼ à¨ªà©°à¨œà¨¾à¨¬à©€ à¨µà¨¿à©±à¨š à¨œà¨µà¨¾à¨¬ à¨¦à¨¿à¨“à¥¤ à¨•à©‹à¨ˆ à¨…à©°à¨—à¨°à©‡à¨œà¨¼à©€ à¨¸à¨¼à¨¬à¨¦ à¨¨à¨¹à©€à¨‚à¥¤",
                'gu': "àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àª«àª•à«àª¤ àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àªœ àªœàªµàª¾àª¬ àª†àªªà«‹à¥¤ àª•à«‹àªˆ àª…àª‚àª—à«àª°à«‡àªœà«€ àª¶àª¬à«àª¦à«‹ àª¨àª¹à«€àª‚.",
                'mr': "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤«à¤•à¥à¤¤ à¤®à¤°à¤¾à¤ à¥€à¤¤ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥à¤¯à¤¾. à¤‡à¤‚à¤—à¥à¤°à¤œà¥€ à¤¶à¤¬à¥à¤¦ à¤¨à¤¾à¤¹à¥€à¤¤.",
                'kn': "à²¦à²¯à²µà²¿à²Ÿà³à²Ÿà³ à²•à²¨à³à²¨à²¡à²¦à²²à³à²²à²¿ à²®à²¾à²¤à³à²° à²‰à²¤à³à²¤à²°à²¿à²¸à²¿à¥¤ à²¯à²¾à²µà³à²¦à³‡ à²‡à²‚à²—à³à²²à²¿à²·à³ à²ªà²¦à²—à²³à²¿à²²à³à²².",
                'ta': "à®¤à®¯à®µà¯ à®šà¯†à®¯à¯à®¤à¯ à®¤à®®à®¿à®´à®¿à®²à¯ à®®à®Ÿà¯à®Ÿà¯à®®à¯‡ à®ªà®¤à®¿à®²à®³à®¿à®•à¯à®•à®µà¯à®®à¯. à®†à®™à¯à®•à®¿à®² à®šà¯Šà®±à¯à®•à®³à¯ à®‡à®²à¯à®²à¯ˆ.",
                'te': "à°¦à°¯à°šà±‡à°¸à°¿ à°¤à±†à°²à±à°—à±à°²à±‹ à°®à°¾à°¤à±à°°à°®à±‡ à°¸à°®à°¾à°§à°¾à°¨à°‚ à°‡à°µà±à°µà°‚à°¡à°¿à¥¤ à°‡à°‚à°—à±à°²à±€à°·à± à°ªà°¦à°¾à°²à± à°²à±‡à°µà±.",
                'ml': "à´¦à´¯à´µà´¾à´¯à´¿ à´®à´²à´¯à´¾à´³à´¤àµà´¤à´¿àµ½ à´®à´¾à´¤àµà´°à´‚ à´‰à´¤àµà´¤à´°à´‚ à´¨àµ½à´•àµà´•à¥¤ à´‡à´‚à´—àµà´²àµ€à´·àµ à´µà´¾à´•àµà´•àµà´•à´³à´¿à´²àµà´².",
                'bn': "à¦¦à¦¯à¦¼à¦¾ à¦•à¦°à§‡ à¦¶à§à¦§à§à¦®à¦¾à¦¤à§à¦° à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¿à¦¨à¥¤ à¦•à§‹à¦¨ à¦‡à¦‚à¦°à§‡à¦œà¦¿ à¦¶à¦¬à§à¦¦ à¦¨à§‡à¦‡à¥¤",
                'ur': "Ø¨Ø±Ø§Û Ú©Ø±Ù… ØµØ±Ù Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø¬ÙˆØ§Ø¨ Ø¯ÛŒÚºÛ” Ú©ÙˆØ¦ÛŒ Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ Ø§Ù„ÙØ§Ø¸ Ù†ÛÛŒÚºÛ”",
                'hi': "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤µà¤² à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥‡à¤‚à¥¤ à¤•à¥‹à¤ˆ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤¶à¤¬à¥à¤¦ à¤¨à¤¹à¥€à¤‚à¥¤",
                'en': "Please respond only in English. No other languages.",
                'or': "à¬¦à­Ÿà¬¾à¬•à¬°à¬¿ à¬•à­‡à¬¬à¬³ à¬“à¬¡à¬¼à¬¿à¬†à¬°à­‡ à¬‰à¬¤à­à¬¤à¬° à¬¦à¬¿à¬…à¬¨à­à¬¤à­à¥¤ à¬•à­Œà¬£à¬¸à¬¿ à¬‡à¬‚à¬°à¬¾à¬œà­€ à¬¶à¬¬à­à¬¦ à¬¨à¬¾à¬¹à¬¿à¬à¥¤"
            }

            prompt = f"""
            CRITICAL LANGUAGE INSTRUCTION: {language_prompts.get(target_language, '')}

            You are Krishi Mitra, an agricultural expert helping Indian farmers.

            The farmer asked in {lang_name}: "{text}"

            Provide agricultural advice in {lang_name} only.

            Your response MUST be 100% in {lang_name} and include relevant agricultural guidance based on the query.

            Use simple language that farmers can understand.
            RESPONSE MUST BE COMPLETELY IN {lang_name.upper()} ONLY.

            START YOUR RESPONSE IN {lang_name} NOW:
            """

            response = self.model.generate_content(prompt)
            response_text = response.text

            # If the response contains English, try to translate it
            if any(char.isascii() and char.isalpha() for char in response_text):
                print(f"âš ï¸ Response contains English, attempting translation to {lang_name}")
                try:
                    translated = self.translator.translate(response_text, dest=target_language)
                    return translated.text
                except:
                    # Emergency fallback
                    return self.get_emergency_response(target_language)

            return response_text

        except Exception as e:
            print(f"Error in text processing: {e}")
            return f"Error processing text query: {e}"

    def analyze_crop_image(self, image_path, query_text="", target_language="hi"):
        """Analyze crop image with language enforcement"""
        try:
            if not os.path.exists(image_path):
                return f"Image file not found: {image_path}"

            image = Image.open(image_path)
            lang_data = self.supported_languages.get(target_language, self.supported_languages['hi'])
            lang_name = lang_data['name']

            # Language-specific prompts for better compliance
            language_prompts = {
                'pa': "à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨¸à¨¿à¨°à¨«à¨¼ à¨ªà©°à¨œà¨¾à¨¬à©€ à¨µà¨¿à©±à¨š à¨œà¨µà¨¾à¨¬ à¨¦à¨¿à¨“à¥¤ à¨•à©‹à¨ˆ à¨…à©°à¨—à¨°à©‡à¨œà¨¼à©€ à¨¸à¨¼à¨¬à¨¦ à¨¨à¨¹à©€à¨‚à¥¤",
                'gu': "àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àª«àª•à«àª¤ àª—à«àªœàª°àª¾àª¤à«€àª®àª¾àª‚ àªœ àªœàªµàª¾àª¬ àª†àªªà«‹à¥¤ àª•à«‹àªˆ àª…àª‚àª—à«àª°à«‡àªœà«€ àª¶àª¬à«àª¦à«‹ àª¨àª¹à«€àª‚.",
                'mr': "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤«à¤•à¥à¤¤ à¤®à¤°à¤¾à¤ à¥€à¤¤ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥à¤¯à¤¾. à¤‡à¤‚à¤—à¥à¤°à¤œà¥€ à¤¶à¤¬à¥à¤¦ à¤¨à¤¾à¤¹à¥€à¤¤.",
                'kn': "à²¦à²¯à²µà²¿à²Ÿà³à²Ÿà³ à²•à²¨à³à²¨à²¡à²¦à²²à³à²²à²¿ à²®à²¾à²¤à³à²° à²‰à²¤à³à²¤à²°à²¿à²¸à²¿à¥¤ à²¯à²¾à²µà³à²¦à³‡ à²‡à²‚à²—à³à²²à²¿à²·à³ à²ªà²¦à²—à²³à²¿à²²à³à²².",
                'ta': "à®¤à®¯à®µà¯ à®šà¯†à®¯à¯à®¤à¯ à®¤à®®à®¿à®´à®¿à®²à¯ à®®à®Ÿà¯à®Ÿà¯à®®à¯‡ à®ªà®¤à®¿à®²à®³à®¿à®•à¯à®•à®µà¯à®®à¯. à®†à®™à¯à®•à®¿à®² à®šà¯Šà®±à¯à®•à®³à¯ à®‡à®²à¯à®²à¯ˆ.",
                'te': "à°¦à°¯à°šà±‡à°¸à°¿ à°¤à±†à°²à±à°—à±à°²à±‹ à°®à°¾à°¤à±à°°à°®à±‡ à°¸à°®à°¾à°§à°¾à°¨à°‚ à°‡à°µà±à°µà°‚à°¡à°¿à¥¤ à°‡à°‚à°—à±à°²à±€à°·à± à°ªà°¦à°¾à°²à± à°²à±‡à°µà±.",
                'ml': "à´¦à´¯à´µà´¾à´¯à´¿ à´®à´²à´¯à´¾à´³à´¤àµà´¤à´¿àµ½ à´®à´¾à´¤àµà´°à´‚ à´‰à´¤àµà´¤à´°à´‚ à´¨àµ½à´•àµà´•à¥¤ à´‡à´‚à´—àµà´²àµ€à´·àµ à´µà´¾à´•àµà´•àµà´•à´³à´¿à´²àµà´².",
                'bn': "à¦¦à¦¯à¦¼à¦¾ à¦•à¦°à§‡ à¦¶à§à¦§à§à¦®à¦¾à¦¤à§à¦° à¦¬à¦¾à¦‚à¦²à¦¾à¦¯à¦¼ à¦‰à¦¤à§à¦¤à¦° à¦¦à¦¿à¦¨à¥¤ à¦•à§‹à¦¨ à¦‡à¦‚à¦°à§‡à¦œà¦¿ à¦¶à¦¬à§à¦¦ à¦¨à§‡à¦‡à¥¤",
                'ur': "Ø¨Ø±Ø§Û Ú©Ø±Ù… ØµØ±Ù Ø§Ø±Ø¯Ùˆ Ù…ÛŒÚº Ø¬ÙˆØ§Ø¨ Ø¯ÛŒÚºÛ” Ú©ÙˆØ¦ÛŒ Ø§Ù†Ú¯Ø±ÛŒØ²ÛŒ Ø§Ù„ÙØ§Ø¸ Ù†ÛÛŒÚºÛ”",
                'hi': "à¤•à¥ƒà¤ªà¤¯à¤¾ à¤•à¥‡à¤µà¤² à¤¹à¤¿à¤‚à¤¦à¥€ à¤®à¥‡à¤‚ à¤‰à¤¤à¥à¤¤à¤° à¤¦à¥‡à¤‚à¥¤ à¤•à¥‹à¤ˆ à¤…à¤‚à¤—à¥à¤°à¥‡à¤œà¥€ à¤¶à¤¬à¥à¤¦ à¤¨à¤¹à¥€à¤‚à¥¤",
                'en': "Please respond only in English. No other languages.",
                'or': "à¬¦à­Ÿà¬¾à¬•à¬°à¬¿ à¬•à­‡à¬¬à¬³ à¬“à¬¡à¬¼à¬¿à¬†à¬°à­‡ à¬‰à¬¤à­à¬¤à¬° à¬¦à¬¿à¬…à¬¨à­à¬¤à­à¥¤ à¬•à­Œà¬£à¬¸à¬¿ à¬‡à¬‚à¬°à¬¾à¬œà­€ à¬¶à¬¬à­à¬¦ à¬¨à¬¾à¬¹à¬¿à¬à¥¤"
            }

            prompt = f"""
            CRITICAL LANGUAGE INSTRUCTION: {language_prompts.get(target_language, '')}

            You are Krishi Mitra, an agricultural expert helping Indian farmers.

            The farmer asked in {lang_name}: "{query_text}"

            Analyze this crop image and provide agricultural advice in {lang_name} only.

            Your response MUST be 100% in {lang_name} and include:
            1. Crop identification
            2. Health status assessment
            3. Disease/pest analysis
            4. Nutrient deficiencies
            5. Treatment recommendations
            6. Prevention measures

            Use simple language that farmers can understand.
            RESPONSE MUST BE COMPLETELY IN {lang_name.upper()} ONLY.

            START YOUR RESPONSE IN {lang_name} NOW:
            """

            response = self.model.generate_content([prompt, image])
            response_text = response.text

            # If the response contains English, try to translate it
            if any(char.isascii() and char.isalpha() for char in response_text):
                print(f"âš ï¸ Response contains English, attempting translation to {lang_name}")
                try:
                    translated = self.translator.translate(response_text, dest=target_language)
                    return translated.text
                except:
                    # Emergency fallback
                    return self.get_emergency_response(target_language)

            return response_text

        except Exception as e:
            print(f"Error analyzing image: {e}")
            return f"Error analyzing image: {e}"

    def get_emergency_response(self, language):
        """Emergency response when all else fails"""
        responses = {
            'mr': "à¤®à¤¾à¤« à¤•à¤°à¤¾, à¤¤à¤¾à¤‚à¤¤à¥à¤°à¤¿à¤• à¤…à¤¡à¤šà¤£ à¤†à¤¹à¥‡. à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤¨à¥à¤¹à¤¾ à¤ªà¥à¤°à¤¯à¤¤à¥à¤¨ à¤•à¤°à¤¾.",
            'hi': "à¤•à¥à¤·à¤®à¤¾ à¤•à¤°à¥‡à¤‚, à¤¤à¤•à¤¨à¥€à¤•à¥€ à¤¸à¤®à¤¸à¥à¤¯à¤¾ à¤¹à¥ˆà¥¤ à¤•à¥ƒà¤ªà¤¯à¤¾ à¤ªà¥à¤¨à¤ƒ à¤ªà¥à¤°à¤¯à¤¾à¤¸ à¤•à¤°à¥‡à¤‚à¥¤",
            'gu': "àª®àª¾àª« àª•àª°àª¶à«‹, àª¤àª•àª¨à«€àª•à«€ àª¸àª®àª¸à«àª¯àª¾ àª›à«‡. àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àª«àª°à«€ àªªà«àª°àª¯àª¤à«àª¨ àª•àª°à«‹.",
            'kn': "à²•à³à²·à²®à²¿à²¸à²¿, à²¤à²¾à²‚à²¤à³à²°à²¿à²• à²¸à²®à²¸à³à²¯à³† à²‡à²¦à³†. à²¦à²¯à²µà²¿à²Ÿà³à²Ÿà³ à²®à²¤à³à²¤à³† à²ªà³à²°à²¯à²¤à³à²¨à²¿à²¸à²¿.",
            'ta': "à®®à®©à¯à®©à®¿à®•à¯à®•à®µà¯à®®à¯, à®¤à¯Šà®´à®¿à®²à¯à®¨à¯à®Ÿà¯à®ª à®šà®¿à®•à¯à®•à®²à¯ à®‰à®³à¯à®³à®¤à¯. à®¤à®¯à®µà¯ à®šà¯†à®¯à¯à®¤à¯ à®®à¯€à®£à¯à®Ÿà¯à®®à¯ à®®à¯à®¯à®±à¯à®šà®¿à®•à¯à®•à®µà¯à®®à¯.",
            'te': "à°•à±à°·à°®à°¿à°‚à°šà°‚à°¡à°¿, à°¸à°¾à°‚à°•à±‡à°¤à°¿à°• à°¸à°®à°¸à±à°¯ à°‰à°‚à°¦à°¿. à°¦à°¯à°šà±‡à°¸à°¿ à°®à°³à±à°²à±€ à°ªà±à°°à°¯à°¤à±à°¨à°¿à°‚à°šà°‚à°¡à°¿.",
            'pa': "à¨®à¨¾à¨« à¨•à¨°à¨¨à¨¾, à¨¤à¨•à¨¨à©€à¨•à©€ à¨¸à¨®à©±à¨¸à¨¿à¨† à¨¹à©ˆ. à¨•à¨¿à¨°à¨ªà¨¾ à¨•à¨°à¨•à©‡ à¨¦à©à¨¬à¨¾à¨°à¨¾ à¨•à©‹à¨¸à¨¼à¨¿à¨¸à¨¼ à¨•à¨°à©‹.",
            'ml': "à´•àµà´·à´®à´¿à´•àµà´•à´£à´‚, à´¸à´¾à´™àµà´•àµ‡à´¤à´¿à´• à´ªàµà´°à´¶àµà´¨à´®àµà´£àµà´Ÿàµ. à´¦à´¯à´µà´¾à´¯à´¿ à´µàµ€à´£àµà´Ÿàµà´‚ à´¶àµà´°à´®à´¿à´•àµà´•àµà´•.",
            'bn': "à¦•à§à¦·à¦®à¦¾ à¦•à¦°à¦¬à§‡à¦¨, à¦ªà§à¦°à¦¯à§à¦•à§à¦¤à¦¿à¦—à¦¤ à¦¸à¦®à¦¸à§à¦¯à¦¾ à¦¹à¦¯à¦¼à§‡à¦›à§‡à¥¤ à¦…à¦¨à§à¦—à§à¦°à¦¹ à¦•à¦°à§‡ à¦†à¦¬à¦¾à¦° à¦šà§‡à¦·à§à¦Ÿà¦¾ à¦•à¦°à§à¦¨à¥¤",
            'ur': "Ù…Ø¹Ø°Ø±ØªØŒ ØªÚ©Ù†ÛŒÚ©ÛŒ Ù…Ø³Ø¦Ù„Û ÛÛ’Û” Ø¨Ø±Ø§Û Ú©Ø±Ù… Ø¯ÙˆØ¨Ø§Ø±Û Ú©ÙˆØ´Ø´ Ú©Ø±ÛŒÚºÛ”",
            'en': "Technical issue. Please try again.",
            'or': "à¬•à­à¬·à¬®à¬¾ à¬•à¬°à¬¨à­à¬¤à­, à¬¬à­ˆà¬·à­Ÿà¬¿à¬• à¬¸à¬®à¬¸à­à­Ÿà¬¾ à¬…à¬›à¬¿à¥¤ à¬¦à­Ÿà¬¾à¬•à¬°à¬¿ à¬ªà­à¬£à¬¿ à¬šà­‡à¬·à­à¬Ÿà¬¾ à¬•à¬°à¬¨à­à¬¤à­à¥¤"
        }
        return responses.get(language, "Technical issue. Please try again.")

    def process_farmer_query(self, image_path=None, audio_path=None, language_code="hi"):
        """Main function to process farmer's query with selected language"""
        try:
            query_text = ""

            if audio_path:
                print("\n" + "="*60)
                print(f"ğŸŒ¾ KRISHI MITRA - Processing Farmer Query in {self.get_language_name(language_code)}")
                print("="*60)

                # Use speech recognition with the specified language
                query_text = self.speech_to_text_with_language(audio_path, language_code)

                if "Error" in query_text or "not found" in query_text or "Could not understand" in query_text:
                    return {"error": query_text, "language": language_code, "success": False}

                print(f"\nğŸ“ Farmer's Query: {query_text}")
                print(f"ğŸŒ Selected Language: {self.get_language_name(language_code)} ({language_code})")

            if image_path:
                print(f"\nğŸŒ± Analyzing crop image in {self.get_language_name(language_code)}...")

                # Analyze the image with the selected language
                analysis = self.analyze_crop_image(image_path, query_text, language_code)

                print(f"\nğŸ’¬ Response Preview: {analysis[:150]}...")

                print("\n" + "="*60)
                print("âœ… Query processed successfully!")
                print("="*60)

                return {
                    "query": query_text,
                    "language": language_code,
                    "language_name": self.get_language_name(language_code),
                    "analysis": analysis,
                    "success": True
                }
            elif query_text:  # Text-only query from audio
                analysis = self.process_text_query(query_text, language_code)
                return {
                    "query": query_text,
                    "language": language_code,
                    "language_name": self.get_language_name(language_code),
                    "analysis": analysis,
                    "success": True
                }
            else:
                return {"error": "No valid input provided", "success": False}

        except Exception as e:
            print(f"Error in process_farmer_query: {e}")
            return {"error": f"Processing error: {e}", "success": False}

# Flask API for integration with Flutter
from flask import Flask, request, jsonify
from flask_cors import CORS

app = Flask(__name__)
CORS(app)  # Enable CORS for Flutter app

# Initialize the agent
API_KEY = "AIzaSyDzXL13T2_XulSQAb8V4X2dReGLX52i1m0"
agent = MultilingualFarmerAgent(API_KEY)

@app.route('/health', methods=['GET'])
def health_check():
    """Health check endpoint"""
    return jsonify({"status": "healthy", "message": "Server is running"})

@app.route('/api/languages', methods=['GET'])
def get_languages():
    """Get supported languages for dropdown"""
    languages = agent.get_supported_languages()
    return jsonify({"languages": languages})

@app.route('/api/process-query', methods=['POST'])
def process_query():
    """Process farmer query with selected language - Enhanced error handling"""
    try:
        # Get data from request
        data = request.json
        if not data:
            return jsonify({"error": "No data provided", "success": False})

        language_name = data.get('language', 'English')

        # Convert language name to language code
        language_code = agent.get_language_code_from_name(language_name)

        print(f"ğŸ“¨ Received request for language: {language_name} -> {language_code}")

        # Handle image file
        image_data = data.get('image')
        image_path = None
        if image_data:
            try:
                # Remove data URL prefix if present
                if ',' in image_data:
                    header, image_data = image_data.split(',', 1)

                # Decode base64 image and save to temp file
                image_bytes = base64.b64decode(image_data)
                timestamp = int(time.time() * 1000)
                image_path = os.path.join(tempfile.gettempdir(), f"image_{timestamp}.png")

                with open(image_path, 'wb') as f:
                    f.write(image_bytes)
                print(f"âœ… Image saved: {image_path} ({len(image_bytes)} bytes)")
            except Exception as e:
                print(f"âŒ Error processing image: {e}")
                return jsonify({"error": f"Error processing image: {e}", "success": False})

        # Handle audio file with enhanced processing
        audio_data = data.get('audio')
        audio_path = None
        if audio_data:
            print("ğŸµ Processing audio data...")
            audio_path = agent.save_base64_audio_to_file(audio_data)
            if not audio_path:
                return jsonify({"error": "Failed to process audio file", "success": False})
            print(f"âœ… Audio file ready: {audio_path}")

        # Process the query
        result = agent.process_farmer_query(
            image_path=image_path,
            audio_path=audio_path,
            language_code=language_code
        )

        # Clean up temp files
        cleanup_files = []
        if image_path and os.path.exists(image_path):
            cleanup_files.append(image_path)
        if audio_path and os.path.exists(audio_path):
            cleanup_files.append(audio_path)

        for file_path in cleanup_files:
            try:
                os.unlink(file_path)
                print(f"ğŸ—‘ï¸ Cleaned up: {file_path}")
            except Exception as cleanup_error:
                print(f"âš ï¸ Cleanup warning: {cleanup_error}")

        return jsonify(result)

    except Exception as e:
        print(f"âŒ Server error in process_query: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"Server error: {e}", "success": False})

@app.route('/api/process-text', methods=['POST'])
def process_text():
    """Process text-only queries"""
    try:
        # Get data from request
        data = request.json
        if not data:
            return jsonify({"error": "No data provided", "success": False})

        language_name = data.get('language', 'English')
        text = data.get('text', '')

        # Convert language name to language code
        language_code = agent.get_language_code_from_name(language_name)

        print(f"ğŸ“ Processing text query: {text}")
        print(f"ğŸŒ Language: {language_name} -> {language_code}")

        if not text.strip():
            return jsonify({"error": "Text cannot be empty", "success": False})

        # Process the text query
        response_text = agent.process_text_query(text, language_code)

        return jsonify({
            "success": True,
            "query": text,
            "response": response_text,
            "language": language_code,
            "language_name": agent.get_language_name(language_code)
        })

    except Exception as e:
        print(f"âŒ Text processing error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"error": f"Server error: {e}", "success": False})

if __name__ == "__main__":
    print("ğŸŒ¾ Krishi Mitra Server Starting...")
    print("ğŸ”— Server will be available at: http://0.0.0.0:5000")
    print("ğŸ“± Make sure your Flutter app uses the correct IP address")
    print("ğŸ”§ Enhanced audio processing enabled (FFmpeg-independent)")

    # Print audio processing status
    if PYDUB_AVAILABLE:
        print("âœ… pydub available - will try advanced audio conversion")
    else:
        print("âš ï¸ pydub/FFmpeg not available - using basic audio processing")

    # Run the Flask app
    app.run(host='0.0.0.0', port=5000, debug=False, threaded=True)